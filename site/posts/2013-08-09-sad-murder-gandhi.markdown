---
layout: post
title: In Which Murder-Gandhi is Sad
date: 2013-08-09 07:27
comments: true
tags: philosophy, feels
---

> I'm trying something new with this post. Due to the outline being less
> coherent than I had originally hoped, I will be leaving the article in shards
> of thought. With any luck, the underlying theme will be evident by the end.

## I

It should come as a surprise to nobody that you aren't the same person that you
were two years ago, nor were you then the same as two years prior. By induction,
it seems safe to assume that you won't be the same person two years in the
future. Since there does not seem to be a discrete moment when you become
different, the self is likely a continuous function; tomorrow you will not be
the same person that you are today.

I consider this revelation to be problematic, indeed to be a seriously egregious
problem - no other philosophical issue in living memory has left me in such a
quandary. If I am not the same person tomorrow as I am today, how can I guarantee
anything which necessarily transcends temporal boundaries? How can I be certain
that I'll accomplish goals far into the future?


## II

Small changes have a habit of cascading into large changes. In an [absolutely
fascinating article][murder Gandhi] (as always is his style), Yvain racounts the
legend of Murder-Gandhi: an entity who is offered \$1,000,000 to lessen his
ideals by 1%. He can see that this is a good trade, and so - being a rational
agent - he accepts. However, the process is iterative and it quickly becomes
evident how slippery a slope this really is: the more he lessens his ideals the
more willing he will be to continue doing so.

If theoretical tiny changes over time can convince Murder-Gandhi (a pacifist,
despite his misleading name) to start killing people, similar theoretical tiny
changes can ruin my less staunch collection of dreams and aspirations.

In the article, Murder-Gandhi solves this problem by creating a schelling point
(a line he has precommitted not to cross) at 95% of his original ideals - as low
a percentage as he is willing to risk before the costs start to outweigh the
benefits. It isn't immediately obvious how to apply this same construction in my
own defense, and so I am left in what can only be described colloquially as "a
pickle".

Given that Murder-Gandhi's solution won't work for me, instead, my plan is to
identify the most-likely route along the path to destruction of my goals. Once
located, perhaps the creation of a policy to prevent these issues from occuring
will be easy.

Perhaps.

[murder Gandhi]: http://lesswrong.com/lw/ase/schelling_fences_on_slippery_slopes/


## III

Strange is an adjective that defines me well. It's not something that I actively
try to hide (have you seen [my blog]?). Personally I don't think that something
can ever be "overthought", and as a result I tend to analyze aspects of life
that most people take for granted. Do I need to sleep? Is food really everything
it's cracked up to be? Can I live without oxygen? *Do I want to be happy?*

Take a sample of everyone you know and ask them that last question. Granted, it
will be a biased sample, but I'll bet you dollars to donuts that *absolutely
every one of them* will say that they'd prefer being happy to the alternative.
It's likely that nobody you know has ever explicitly thought about it before -
given the choice, why would you even consider not being happy?

Like I said, I'm a little strange. Understandably, the way I see the world is
also rather queer. Due to larger-than-average [inferential differences] it seems
that the things that I want are not the things that most people want, and this
can make relating to others difficult.

[my blog]: http://sandymaguire.me
[inferential differences]: http://lesswrong.com/lw/kg/expecting_short_inferential_distances/


## IV

Emotions are stupid.

This is one of my more substantial beliefs. Due to hardware limitations, I
necessarily experience them, but preferentially I would give them up if I could.
Emotions get in the way of thinking, and cognition seems to be one of my
stronger comparative advantages.

The happy/sad emotional spectrum - singled out for the sake of my argument - is
particularly (although not uniquely) troublesome. Sadness is obviously bad for
long-term survival, but happiness leads to contentment and, as Kahneman points
out in [Thinking, Fast and Slow], greatly increases the likelihood of making
errors in cognition.

"Why is contentment a negative prospect?" you might wonder. I say as much
because being content implies that there is no burning desire to accomplish
more. In this respect, contentment is at odds with the completion of goals.

When framed like this, it appears that there is no defensible location on the
continuum on which to stand. I mean, if I really had to choose between longevity
and exceptional success, I would have to go with the former. This seems like an
artificial question, however; why should I have to choose?

After a moment's thought, it becomes apparent that I needn't be stationary on
the happiness scale; it is a fool who considers his stance static on issues of a
complicated nature. Indeed, the ideal solution here is to be happy *when, and
only when* it suits me. Furthermore, happy-space is large; I can be happy about
some things while simultaneously upset about others.

And herein lies the key to a successful philosophy: being happy about the
present ensures that I obtain the longevity bonuses of being maintainable until
the distant future. Simultaneously, being upset by my current trajectory in life
ensures that I will always be working to improve myself; that I will never fall
victim to contentment.

[Thinking, Fast and Slow]: http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374533555


## V

The philosophy propounded acts as its own schelling fence in the face of
continuous compounding over time, and as such, it is thus temporally consistent.
Unlike the pills given to Murder-Gandhi, this strategy does not discount
hyperbolically; instead it rewards short-term adherence, ensuring coherence in
the long-run.

Somehow I've unwittingly stumbled upon a general strategy to prevent undesired
changes in a unspecified continuous function. If you can prevent the derivative
of this function from ever going in the wrong direction, you can ensure the
correct result in the long run. It sounds [really obvious][hindsight bias] when
phrased this way (assuming you know a [little bit about calculus][derivatives]),
but only if you had thought to ask the question in the first place.

You can call me strange if you'd like, but it feels *really good* to apply
calculus to real life.

[hindsight bias]: http://lesswrong.com/lw/il/hindsight_bias/
[derivatives]: http://en.wikipedia.org/wiki/Derivative

